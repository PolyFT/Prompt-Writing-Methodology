# 🧠 科研场景下面向大模型的 Prompt 编写规范  
*Research-Oriented Prompt Writing Methodology for Large Language Models*

---

## 📌 文档定位说明

这是一份系统性指南，旨在规范科研场景中使用大语言模型（LLM）进行
**提示词（Prompt）编写**时的策略、原则与约束。

规范的目标是解决科研场景中 AI 辅助写作与文本生成中的常见问题：

- **语义漂移**  
- **概念外推**  
- **结论越权**  
- **科研责任边界模糊**  

确保科研文本在 **学术精准性、表达规范性与责任明确性** 上始终保持
**可控、可追溯、可审查**。

---

## 一、制定背景与核心立场

大语言模型正逐渐嵌入科研写作、方法论构建、图示设计、学术沟通等强约束学术场景。Prompt 的核心功能也发生转变——

从"交互指令"升级为：
> **决定科研文本质量与学术合规性的关键环节**

### 核心立场：

- LLM 是**受约束的科研辅助工具**，而非创造性主导者。
- Prompt 是一种**科研输入的模型化表达**，不容随意。
- **科研判断、结论与责任主体**永远归属于研究者本身。
- AI 输出只能起**协作辅助作用**，不得替代科研决策或价值判断。

---

## 二、适用范围

适用于：

1. **高强度学术写作场景**
   - SCI 期刊论文写作及修改
   - 方法学描述、结果解读与图表整理
   - 各级科研项目文本编制
   - 学术审稿意见回复

2. **要求一致性与复现性的内部科研文档**

不适用于：
  
- 自由探索、创意发散的开放式写作。
- 非科研用途的问答场景。
  
---

## 三、Prompt 的本质角色

科研情境中的 Prompt 应被视为：  

1. **研究边界的正式化定义**。
2. **限制信息处理与生成范围的显性约定**。
3. **输入行为对模型生成的结构化建模**。

一个优秀的科研 Prompt，其功能是：
> **防止模型越权，根据既定规范交付可靠输出**  

---

## 四、科研 Prompt 的十条硬约束

1. 禁止要求生成新科学问题或研究假设。
2. 禁止要求进行价值评估或创新性判断。
3. 禁止补充未明确输入的实验事实。
4. 禁止引入未输入的研究对象或机理解释。
5. 禁止使用含糊的外推性措辞（如“可能”）。
6. 禁止要求结论的总结升级或学术地位评判。
7. 禁止将模型作为科研结论的唯一来源。
8. Prompt 必须显式限定任务边界与输出范围。
9. Prompt 必须明确模型仅为语言与结构工具。
10. 所有最终学术判断必须回溯至研究者本人。

---

## 五、合规 Prompt 的基本特征

1. **任务角色清晰**：专注于改写、压缩、重组语言结构。
2. **语义边界明确**：禁止加入新增内容或外延结论。
3. **输出要求中立**：文本风格应偏学术性、中立性。
4. **模型角色约束**：仅作为语言与结构辅助工具。

---

## 六、不合规 Prompt 的风险特征

以下问题应避免：

- 要求生成创新点、突破性意义的总结。
- 要求判断科学价值或推断未来研究可能。
- 无边界限制却要求“系统分析”。
- 使用角色越权的表达（如“请作为专家”）。

---

## 七、四步法合规执行指南

科研中使用 LLM 可遵循以下策略执行：  

1. **自查行为边界**  
    明确需要研究者亲自完成的内容。
2. **构建受限 Prompt**  
    限制生成仅基于已知信息进行语言处理。  
3. **回收输出责任**  
    所有生成文本需人工审校与确认。
4. **多轮反馈优化**  
    采用迭代生成方式提高文本规范性。

---

## 八、科研责任与合规声明

本规范的唯一目标：  
> **约束 Prompt 编写行为，避免越权生成。**  

科研文本生成过程中的：

- **学术内容的准确性；**
- **研究责任的承担主体；**
- **生成文本的最终合规性；**

均由具体使用者负责，规范本身不提供任何形式的学术担保。

---

## 九、动态更新与维护指南

此文档可作为科研团队长期使用的操作规范，并依据以下原则适时调整：

1. 随科研实践经验的积累，增加适配性规范。
2. 考虑 LLM 技术发展的新要求，扩展约束条款。

### 最高准则：

始终确保文本生成行为符合以下底线：  
- **科研责任不可转移；**
- **语义边界优先收敛。**

---